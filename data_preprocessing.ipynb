{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c220ba77-c2e0-4bb5-acc2-2042f1f49d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294182c6-18ea-4b82-928c-c2608c5cbc80",
   "metadata": {},
   "source": [
    "# Merge with issuers to get context info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35abe0f4-35e2-462d-adee-0a078f7f0223",
   "metadata": {},
   "outputs": [],
   "source": [
    "issuers_ddf = dd.read_csv(\"data/issuer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f65262-4fde-4a88-a8ed-fed05cab8b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issuerId</th>\n",
       "      <th>osl_id</th>\n",
       "      <th>symbol</th>\n",
       "      <th>issuerSign</th>\n",
       "      <th>name</th>\n",
       "      <th>isActive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-csv, 1 graph layer</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              issuerId  osl_id  symbol issuerSign    name isActive\n",
       "npartitions=1                                                     \n",
       "                 int64  object  object     object  object     bool\n",
       "                   ...     ...     ...        ...     ...      ...\n",
       "Dask Name: read-csv, 1 graph layer"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issuers_ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d61ab540-d50a-42b2-a35c-862167899c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_ddf = dd.read_parquet(\"data/tokenized_msg.parquet\", npartitions=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c49f522-74cc-4b4c-a033-d7ffc1923ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_ddf.compute().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "364df87e-6ea2-4e43-aa41-f9fc58e41295",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_issuer_df = msg_ddf.merge(issuers_ddf, on=\"issuerId\").compute()#, validate=\"many_to_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8321d5df-c59f-427c-ab0e-36270c387fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_issuer_df[\"publishedTime_dt\"] = pd.to_datetime(msg_issuer_df[\"publishedTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d676b27-f490-4088-956a-2edf73f246fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_issuer_df.to_parquet(\"msgs_w_issuer.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5c8b4-7483-46f9-932f-57a2efcfb27f",
   "metadata": {},
   "source": [
    "### Use publish time as indicator for which days and history to use\n",
    "- If published Day 0, AFTER 16:30 (closing hours) -> Compare to next TRADING day\n",
    "- If published Day 0, BEFORE 16:30 -> Compare to Same day\n",
    "- Exclude holidays for now\n",
    "- Weekends -> Next trading day is automatically from history\n",
    "\n",
    "#### Data analysis\n",
    "- Date 2020-05-10 is (May) is Nan for multiple companies\n",
    "- Some companies have multiple missing days\n",
    "- -> Remove those and remove messages if they are within that timespan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b3dc09-8e74-4db7-aac2-6cdc5349f87c",
   "metadata": {},
   "source": [
    "##### Scaleable approach?\n",
    "1. Add issuerId info to each stock price row\n",
    "2. For each stock row, add all featues, backwards and forwards\n",
    "3. Merge all company histories\n",
    "4. For each message, based on published time and issuer id, index the relevant trading day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1320a210-b3bb-4374-99fe-9757ff58a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a8129f95-bc6d-49bd-9a5d-eb9b9f636eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_history_path = Path(\"data/stock_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1c54b-2143-467c-a207-f2fe0b0ba96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AKRBP = pd.read_csv(\"data/stock_history/AKRBP.csv\", header=1, parse_dates=[\"Date\"]).set_index(\"Date\")\n",
    "AKRBP.iloc[:, :-1] = AKRBP.iloc[:, :-1].apply(lambda col: col.str[3:])\n",
    "AKRBP[\"Volume\"] = AKRBP[\"Volume\"].str.replace(\",\", \"\")\n",
    "AKRBP = AKRBP.astype(float)\n",
    "#.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5d083884-e1c2-431c-93ea-6e42140ce96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAILY_COLS = [\"Close\", \"Open\", \"High\", \"Low\"]\n",
    "daily_cols = [x.lower() for x in DAILY_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2019a90c-b449-4e5c-b872-1b9715a940a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean(path):\n",
    "    df = pd.read_csv(path, header=1, parse_dates=[\"Date\"], thousands=\",\", index_col=\"Date\",\n",
    "                     converters={k:lambda col: float(col[3:].replace(\",\", \"\")) if \"kr\" in col else np.nan for k in DAILY_COLS},\n",
    "                     dtype={\"Volume\": float})#.set_index(\"Date\")\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df[\"symbol\"] = path.stem\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "60b26ab7-17a0-48d3-a957-72ff524ddf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_intraday_feats(df):\n",
    "    # Price action and volume moving averages\n",
    "    # INTRA DAY AND GAP\n",
    "    other_vals = {\"dol_volume\": df[daily_cols].mean(axis=\"columns\").mul(df[\"volume\"], axis=0),\n",
    "                \"intra_day_high_low_pct\": (df[\"high\"] - df[\"low\"]).divide(df[\"low\"])*100,\n",
    "              \"intra_day_open_close_pct\": (df[\"close\"] - df[\"open\"]).divide(df[\"open\"])*100,\n",
    "              \"gap_pct\": (df[\"close\"] - df[\"open\"].shift(1)).divide(df[\"open\"].shift(1))*100\n",
    "             }\n",
    "    return df.assign(**other_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "db684fd9-b5fb-464b-9b0c-8705f8e67cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rolling_feats(df):\n",
    "    \"\"\"Extracting moving features based on dollar volume and daily prices.\n",
    "    Currently it uses the average daily price as a compromise.\"\"\"\n",
    "    rolling_vals = [3, 7, 15, 30]\n",
    "    action_mean = df[daily_cols].mean(axis=\"columns\")\n",
    "    \n",
    "    # Exponential moving averages of prices\n",
    "    ewms = {f\"ewm_{k}\": action_mean.ewm(span=k).mean() for k in rolling_vals}\n",
    "    ewms_std = {f\"ewm_std_{k}\": action_mean.ewm(span=k).std() for k in rolling_vals}\n",
    "    \n",
    "    # EMA for dollar volume\n",
    "    dol_vol_ewm = {f\"dol_vol_ewm_{k}\": df[\"volume\"].ewm(span=k).mean() for k in rolling_vals}\n",
    "    dol_vol_ewm_std = {f\"dol_vol_ewm_std_{k}\": df[\"volume\"].ewm(span=k).std() for k in rolling_vals}\n",
    "    return df.assign(**{**ewms, **ewms_std, **dol_vol_ewm, **dol_vol_ewm_std})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "28e00e7e-a7d0-4a49-b240-a1e85205968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_future_features(df):\n",
    "    \"\"\"Calculate periodic change in percentage for avg daily price.\n",
    "    Consistent with rolling, so if average is moved to open/close, so should the other.\n",
    "    \"\"\"\n",
    "    pct_changes = {f\"d{k}_avg_pct\": df[\"close\"].pct_change(periods=k) * 100 for k in rolling_vals}\n",
    "    return df.assign(**pct_changes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d3e58a8d-4886-4878-8a09-12d36ebad1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 209 ms, sys: 8.99 ms, total: 218 ms\n",
      "Wall time: 254 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_df = load_clean(stock_history_path / \"AKRBP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "279e5c44-18e5-4102-aebd-3a92edc61382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.92 ms, sys: 2.15 ms, total: 12.1 ms\n",
      "Wall time: 18.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "intra_df = extract_intraday_feats(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1f63cb79-31b5-4117-b29c-31a3190ee502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.2 ms, sys: 7.23 ms, total: 20.5 ms\n",
      "Wall time: 23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rolling_df = extract_rolling_feats(intra_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5e447251-ac79-467f-b209-b07a9afe810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.23 ms, sys: 947 µs, total: 9.17 ms\n",
      "Wall time: 8.82 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "future_df = extract_future_features(rolling_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "cfab347e-7e17-4371-a67c-c6a6e3769a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df):\n",
    "    \"\"\"Process each df\"\"\"\n",
    "    intra_feats = extract_intraday_feats(df)\n",
    "    rolling_feats = extract_rolling_feats(intra_feats)\n",
    "    future_df = extract_future_features(rolling_feats)\n",
    "    return future_df.set_index([\"symbol\", future_df.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "dc0b3d8e-6fa2-4eb3-b52d-dba3a3ee809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKLIST = [\"KRAB\", \"CSS\", \"ALT\", \"ECIT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "eac2def0-392c-4537-a3ed-27d753c89c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New blacklist: SMCRT\n",
      "New blacklist: MVW\n",
      "New blacklist: HMONY\n",
      "New blacklist: NATTO\n",
      "New blacklist: LYTIX\n",
      "New blacklist: SMOP\n",
      "New blacklist: NORDH\n",
      "New blacklist: KOMPL\n",
      "New blacklist: MAS\n",
      "New blacklist: NTI\n",
      "New blacklist: ELO\n",
      "New blacklist: AFISH\n",
      "CPU times: user 51.6 s, sys: 293 ms, total: 51.9 s\n",
      "Wall time: 52.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfs = []\n",
    "for idx, hist_path in enumerate(list(stock_history_path.glob(\"*.csv\")), start=1):\n",
    "    try: \n",
    "        if hist_path.stem in BLACKLIST:\n",
    "            continue\n",
    "        #print(f\"READING {idx}: {hist_path.stem}\")\n",
    "        df = load_clean(hist_path)\n",
    "        dfs.append(process_df(df))\n",
    "    except pd.errors.ParserError as e:\n",
    "        if \"header=1\" in str(e):\n",
    "            print(\"New blacklist:\", hist_path.stem)\n",
    "            BLACKLIST.append(hist_path.stem)\n",
    "        else:\n",
    "            print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "58ea35db-fe96-457c-9688-465a0f44652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_history = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "bbf63f09-b743-4302-95fc-296ff79e3c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     315.000000\n",
       "mean     1933.326984\n",
       "std      1791.382119\n",
       "min         0.000000\n",
       "25%       157.500000\n",
       "50%      1566.000000\n",
       "75%      3593.000000\n",
       "max      5018.000000\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_history.count(level=0)[\"close\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ba641047-a2da-44d5-b39e-42e502c613fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(615065, 29)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3cdb8da1-ba63-4a98-853d-d3e405d3ee9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 933 ms, sys: 500 ms, total: 1.43 s\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "complete_history.to_parquet(\"data/processed_history.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
